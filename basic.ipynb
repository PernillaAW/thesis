{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1c936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkConf, StorageLevel\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.types import FloatType\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1e8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setMaster('local[*]').setAppName(\"CarAccidents\") \\\n",
    ".set(\"spark.driver.memory\", \"6g\") \\\n",
    ".set(\"spark.executor.memory\", \"1g\") \\\n",
    ".set(\"spark.driver.memoryOverhead\", \"256m\") \\\n",
    ".set(\"spark.executor.memoryOverhead\", \"256m\") \\\n",
    ".set(\"spark.sql.files.maxPartitionBytes\", \"64m\") \\\n",
    ".set(\"spark.sql.execution.arrow.pyspark.enabled\", \"false\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1926f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.options(header=True, escape='\"', multiline=True,\n",
    "                          ).parquet('hdfs://localhost:9000/converted_numbers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aadda4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic = df.select([\"Severity\", \"State\", \"Description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79b8998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity     1       2       3     4\n",
      "State                               \n",
      "AL         325   37309   10529   893\n",
      "AR          20    9005     301  1201\n",
      "AZ        3601   66972    8182  2450\n",
      "CA        4960  692053  131054  6195\n",
      "CO         468   27239   12732  3368\n",
      "CT          39   24859    8118  2068\n",
      "DC          66    7710     509   367\n",
      "DE         122    5659     359   787\n",
      "FL        3290  365076   50804  6285\n",
      "GA         513   45543   29954  6193\n",
      "IA          23    8247    3456   960\n",
      "ID           1    4690     107   283\n",
      "IL         781   51879   28396  2097\n",
      "IN         166   21978    7618  2692\n",
      "KS          22    6723    1952   301\n",
      "KY         133    9018    6149   559\n",
      "LA        1201   62292    8555   903\n",
      "MA         731   19563    8818   270\n",
      "MD         193   41559    9162  4454\n",
      "ME           1    1085     174    57\n",
      "MI         548   56114   20128  3717\n",
      "MN         231   77033   14635   412\n",
      "MO         116   22721   12301  1246\n",
      "MS          16    5234    1695   405\n",
      "MT           0   13030      75   206\n",
      "NC        2521  143972   14446  4880\n",
      "ND           0    1370      10     8\n",
      "NE          56   11848    2061   243\n",
      "NH          38    3771    1007   114\n",
      "NJ          97   52815   10126  2736\n",
      "NM          62    3201    1392   270\n",
      "NV          56    8277    1781   337\n",
      "NY         592  130240   33966  5132\n",
      "OH         815   38969   15245  3164\n",
      "OK         637   36968    3385   220\n",
      "OR         651   78820    4817  2930\n",
      "PA         823  119305   15046  7474\n",
      "RI         101    4193    3702    58\n",
      "SC        3089  160235   20550  1506\n",
      "SD           0      88       1    21\n",
      "TN        1141   65955   14080  1671\n",
      "TX        2079  219438   58293  3411\n",
      "UT         290   35586    7214   717\n",
      "VA        1503  106215   23851  8403\n",
      "VT           0     302     116    41\n",
      "WA         445   35980   14889  1939\n",
      "WI          41   10682    4731  1712\n",
      "WV           0    5947     241   399\n",
      "WY           0    1184      81   230\n"
     ]
    }
   ],
   "source": [
    "df_pandas = df_basic.toPandas()\n",
    "\n",
    "fifty_percent = int(len(df_pandas) * 0.5)\n",
    "df_basic_50 = pd.DataFrame()\n",
    "df_basic_50 = pd.concat([df_basic_50, df_pandas.iloc[0:fifty_percent]], ignore_index=True)\n",
    "table = pd.crosstab(df_basic_50[\"State\"], df_basic_50[\"Severity\"])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41eaec19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15660\\4250345566.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspark_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_basic_50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mspark_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'overwrite'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hdfs://localhost:9000/basic_50/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\perni\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\perni\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\perni\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, pdf, schema, timezone)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\perni\\anaconda3\\envs\\pyspark_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mspecific\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6203\u001b[0m             Return a copy when ``copy=True`` (be very careful setting\n\u001b[1;32m-> 6204\u001b[1;33m             \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0mto\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mpropagate\u001b[0m \u001b[0mto\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6205\u001b[0m             pandas objects).\n\u001b[0;32m   6206\u001b[0m         \u001b[0merrors\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6207\u001b[0m             \u001b[0mControl\u001b[0m \u001b[0mraising\u001b[0m \u001b[0mof\u001b[0m \u001b[0mexceptions\u001b[0m \u001b[0mon\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(df_basic_50)\n",
    "\n",
    "spark_df.repartition(7).write.mode('overwrite').parquet('hdfs://localhost:9000/basic_50/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
